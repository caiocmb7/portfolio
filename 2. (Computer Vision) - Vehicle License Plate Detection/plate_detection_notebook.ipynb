{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635ffe9e-4e3a-400e-bd18-39dfd1f346e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytesseract\n",
      "Version: 0.3.10\n",
      "Summary: Python-tesseract is a python wrapper for Google's Tesseract-OCR\n",
      "Home-page: https://github.com/madmaze/pytesseract\n",
      "Author: Samuel Hoffstaetter\n",
      "Author-email: samuel@hoffstaetter.com\n",
      "License: Apache License 2.0\n",
      "Location: c:\\users\\caio_barros\\appdata\\local\\anaconda3\\envs\\ocrproject\\lib\\site-packages\n",
      "Requires: packaging, Pillow\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04e42e6b-e191-462e-8694-a7cff4e37421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import cv2\n",
    "import easyocr\n",
    "import imutils\n",
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pytesseract\n",
    "import nb_black\n",
    "import fastwer\n",
    "from PIL import Image, ImageEnhance\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext lab_black\n",
    "\n",
    "\n",
    "# Jaccard metric uses\n",
    "REAL_VALUES = {\n",
    "    \"Cars299.jpg\": \"SDN7484U\",\n",
    "    \"Cars393.jpg\": \"M771276\",\n",
    "    \"Cars418.jpg\": \"OX65AWD\",\n",
    "    \"Cars73.jpg\": \"TN99F2378\",\n",
    "    \"Cars14.jpg\": \"ALR486\",\n",
    "    \"Cars104.jpg\": \"NL60LXB\",\n",
    "    \"Cars105.jpg\": \"SBA1234A\",\n",
    "    \"Cars123.jpg\": \"HR26BC5514\",\n",
    "    \"Cars167.jpg\": \"15-LK-10898\",\n",
    "    \"Cars17.jpg\": \"YSX213\",\n",
    "    \"Cars197.jpg\": \"LR33TEE\",\n",
    "    \"Cars198.jpg\": \"MH01AV8866\",\n",
    "    \"Cars199.jpg\": \"MH01AE8017\",\n",
    "    \"Cars287.jpg\": \"DL7CN5617\",\n",
    "    \"Cars293.jpg\": \"GBI8TCE\",\n",
    "    \"Cars301.jpg\": \"G526JHD\",\n",
    "    \"Cars302.jpg\": \"JPK6546\",\n",
    "    \"Cars305.jpg\": \"SGQ51JU\",\n",
    "    \"Cars432.jpg\": \"DL49AK49\",\n",
    "    \"Cars52.jpg\": \"MH15BD8877\",\n",
    "}\n",
    "REAL_VALUES_DF = pd.DataFrame(\n",
    "    list(REAL_VALUES.items()), columns=[\"Image\", \"real_plate\"]\n",
    ")\n",
    "\n",
    "\n",
    "class PlateRecognition:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __filters(self, img):\n",
    "        \"\"\"\n",
    "        Preprocessing images for the OpenCV method.\n",
    "\n",
    "        Args:\n",
    "            img: image that will be preprocessed\n",
    "\n",
    "        Return:\n",
    "            preprocessed image with some new features -> gray, bilateralfilter and edged\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        bfilter = cv2.bilateralFilter(gray, 11, 17, 17)  # Noise reduction\n",
    "        edged = cv2.Canny(bfilter, 30, 200)  # Edge detection\n",
    "        return gray, bfilter, edged\n",
    "\n",
    "    def __search_plate_and_crop(self, img, edged, gray):\n",
    "        \"\"\"\n",
    "        Use the preprocessed images to find countours and consequently crop the images\n",
    "\n",
    "        Args:\n",
    "            img: real image\n",
    "            edged: edged image (_filters method)\n",
    "            gray: gray image (_filters method)\n",
    "\n",
    "        Return:\n",
    "            image with the contours, his coordinates and the cropped.\n",
    "        \"\"\"\n",
    "        keypoints = cv2.findContours(\n",
    "            edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        contours = imutils.grab_contours(keypoints)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "        location = 0\n",
    "        for contour in contours:\n",
    "            approx = cv2.approxPolyDP(contour, 10, True)\n",
    "            if len(approx) == 4:\n",
    "                location = approx\n",
    "                break\n",
    "        mask = np.zeros(gray.shape, np.uint8)\n",
    "        new_image = cv2.drawContours(mask, [location], 0, 255, -1)\n",
    "        new_image = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        (x, y) = np.where(mask == 255)\n",
    "        (x1, y1) = (np.min(x), np.min(y))\n",
    "        (x2, y2) = (np.max(x), np.max(y))\n",
    "        cropped_image = gray[x1 : x2 + 1, y1 : y2 + 1]\n",
    "        return new_image, approx, cropped_image\n",
    "\n",
    "    def __create_new_folder(self, path, folder_name):\n",
    "        \"\"\"\n",
    "        Create a new folder based on the args.\n",
    "\n",
    "        Args:\n",
    "            path: path that will be created the new folder\n",
    "            folder_name: the name of the folder that will be created in this path.\n",
    "\n",
    "        Return:\n",
    "            path of the new folder.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            current_path = os.getcwd()\n",
    "            os.chdir(\".\")\n",
    "            path = os.getcwd()\n",
    "            full_path = os.path.join(path, folder_name)\n",
    "            os.makedirs(full_path)\n",
    "            os.chdir(current_path)\n",
    "            return full_path\n",
    "        except OSError as error:\n",
    "            print(f\"-- Folder already created: {folder_name}\")\n",
    "            full_path = os.path.join(path, folder_name)\n",
    "            return full_path\n",
    "\n",
    "    def __plot_images(self, img1, img2, title1=\"\", title2=\"\"):\n",
    "        fig = plt.figure(figsize=[15, 15])\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.imshow(img1, cmap=\"gray\")\n",
    "        ax1.set(xticks=[], yticks=[], title=title1)\n",
    "\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.imshow(img2, cmap=\"gray\")\n",
    "        ax2.set(xticks=[], yticks=[], title=title2)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def __resize_images(self, img_path):\n",
    "        \"\"\"\n",
    "        Increase the image size if it is too small\n",
    "\n",
    "        Args:\n",
    "            img: real image\n",
    "\n",
    "        Return:\n",
    "            image with four times bigger.\n",
    "        \"\"\"\n",
    "        min_size = 500\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        if width < min_size or height < min_size:\n",
    "            if width < height:\n",
    "                new_width = min_size\n",
    "                new_height = int(height * (min_size / width))\n",
    "            else:\n",
    "                new_height = min_size\n",
    "                new_width = int(width * (min_size / height))\n",
    "            img = img.resize((new_width, new_height), Image.BICUBIC)\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        return img\n",
    "\n",
    "    def __preprocess_images(self, img_path):\n",
    "        new_width = 115\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        if width < new_width:\n",
    "            new_height = int(height * new_width / width)\n",
    "            img = img.resize((new_width, new_height))\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        enhanced_img = enhancer.enhance(2.0)\n",
    "        return enhanced_img\n",
    "\n",
    "    def __preprocess_jaccard(self, df):\n",
    "        \"\"\"\n",
    "        Function to preprocess a pandas DataFrame containing columns 'real_plate' and 'predicted_plate'.\n",
    "\n",
    "        Args:\n",
    "            DataFrame to be preprocessed.\n",
    "\n",
    "        Return:\n",
    "            Preprocessed DataFrame.\n",
    "        \"\"\"\n",
    "        for index, row in df.iterrows():\n",
    "            real_plate = row[\"real_plate\"]\n",
    "            predicted_plate = row[\"predicted_plate\"]\n",
    "\n",
    "            if len(predicted_plate) < len(real_plate):\n",
    "                predicted_plate = predicted_plate.ljust(len(real_plate))\n",
    "            elif len(real_plate) < len(predicted_plate):\n",
    "                real_plate = real_plate.ljust(len(predicted_plate))\n",
    "\n",
    "            df.at[index, \"real_plate\"] = real_plate\n",
    "            df.at[index, \"predicted_plate\"] = predicted_plate\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __jaccard_evaluation(self, real_df, predicted_df):\n",
    "        \"\"\"\n",
    "        Function to use jaccard metric to evaluate OCR outputs (results)\n",
    "\n",
    "        Args:\n",
    "            real_df: manual labeled dataframe about the real dataset with Image.jpg and plate\n",
    "            predicted_df: dataframe outputs from OCR methods\n",
    "\n",
    "        Return:\n",
    "            Jaccard value metric\n",
    "        \"\"\"\n",
    "        df = real_df.merge(predicted_df)\n",
    "        df.rename({\"Plate\": \"predicted_plate\"}, axis=1, inplace=True)\n",
    "        df_aux = df\n",
    "        df = self.__preprocess_jaccard(df)\n",
    "        real_list = df[\"real_plate\"].tolist()\n",
    "        predicted_list = df[\"predicted_plate\"].tolist()\n",
    "        jaccard_metric = jaccard_score(real_list, predicted_list, average=\"weighted\")\n",
    "        print(f\"Jaccard score: {jaccard_metric}\")\n",
    "        return df_aux\n",
    "\n",
    "    def __ocr_metrics(self, real_df, predicted_df):\n",
    "        df = real_df.merge(predicted_df)\n",
    "        df.rename({\"Plate\": \"predicted_plate\"}, axis=1, inplace=True)\n",
    "        df[\"predicted_plate\"] = df[\"predicted_plate\"].str.replace(\n",
    "            \" \", \"\"\n",
    "        )  # remove blank spaces to improve metrics\n",
    "        for index, row in df.iterrows():\n",
    "            if pd.isnull(row[\"predicted_plate\"]):\n",
    "                row[\"predicted_plate\"] = \"\"\n",
    "            cer = fastwer.score_sent(\n",
    "                row[\"predicted_plate\"], row[\"real_plate\"], char_level=True\n",
    "            )\n",
    "            wer = fastwer.score_sent(\n",
    "                row[\"predicted_plate\"], row[\"real_plate\"], char_level=False\n",
    "            )\n",
    "            df.loc[df[\"Image\"] == row[\"Image\"], \"CER\"] = round(cer, 2)\n",
    "            df.loc[df[\"Image\"] == row[\"Image\"], \"WER\"] = round(wer, 2)\n",
    "\n",
    "        mean_cer = round(df[\"CER\"].mean(), 2)\n",
    "        mean_wer = round(df[\"WER\"].mean(), 2)\n",
    "        print(f\"Mean CER = {mean_cer}%\\nMean WER = {mean_wer}%\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def OpenCVeasy(self, path, folder_name, save_fig=False, show_steps=False):\n",
    "        \"\"\"\n",
    "        Use threshold, edge detection to find countours for car plate detection. EasyOCR for image to text recognition.\n",
    "\n",
    "        Args:\n",
    "            path: directory path which contains the images\n",
    "            folder_name: directory path which will contain the results\n",
    "            show_steps: to show the steps of the preprocessing images\n",
    "\n",
    "        Return:\n",
    "            DataFrame.csv with the labeled plate of each car (image)\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.folder_name = folder_name\n",
    "        df_lista = []\n",
    "\n",
    "        full_path = self.__create_new_folder(path, folder_name)\n",
    "\n",
    "        for dir, subarch, archives in os.walk(path):\n",
    "            for path_image in archives:\n",
    "                try:\n",
    "                    img = cv2.imread(path + \"/\" + str(path_image))\n",
    "                    img = self.__resize_images(img)\n",
    "                    gray, bfilter, edged = self.__filters(img)\n",
    "                    new_image, approx, cropped_image = self.__search_plate_and_crop(\n",
    "                        img, edged, gray\n",
    "                    )\n",
    "\n",
    "                    reader = easyocr.Reader([\"en\"])\n",
    "                    result = reader.readtext(cropped_image)\n",
    "\n",
    "                    text = result[0][-2]\n",
    "                    df_lista.append((path_image, text.upper()))\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    res = cv2.putText(\n",
    "                        img,\n",
    "                        text=text,\n",
    "                        org=(approx[1][0][0], approx[2][0][1] + 30),\n",
    "                        fontFace=font,\n",
    "                        fontScale=0.7,\n",
    "                        color=(0, 255, 0),\n",
    "                        thickness=3,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "                    res = cv2.rectangle(\n",
    "                        img, tuple(approx[0][0]), tuple(approx[2][0]), (0, 255, 0), 3\n",
    "                    )\n",
    "                    # plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))\n",
    "                    if save_fig == True:\n",
    "                        plt.savefig(full_path + \"/\" + path_image)\n",
    "                except IndexError as IE:\n",
    "                    print(f\"\\n\\nIndex Error in {path_image}\")\n",
    "                    continue\n",
    "                except Exception as error:\n",
    "                    print(f\"\\n\\nImage Error {path_image}\")\n",
    "                    continue\n",
    "\n",
    "        df_aux = pd.DataFrame(df_lista)\n",
    "        df_aux.rename(columns={0: \"Image\", 1: \"Plate\"}, inplace=True)\n",
    "        df = df_aux.sort_values(\"Image\").to_csv(\n",
    "            full_path + \"/\" + \"opencv_results.csv\", index=False\n",
    "        )\n",
    "\n",
    "        if show_steps == True:\n",
    "            self.__plot_images(img, gray, title1=\"original\", title2=\"gray\")\n",
    "            self.__plot_images(gray, bfilter, title1=\"gray\", title2=\"bfilter\")\n",
    "            self.__plot_images(bfilter, edged, title1=\"bfilter\", title2=\"edged\")\n",
    "            self.__plot_images(\n",
    "                img, cropped_image, title1=\"original\", title2=\"cropped_image\"\n",
    "            )\n",
    "\n",
    "        df = pd.read_csv(full_path + \"/\" + \"opencv_results.csv\")\n",
    "        df_final = self.__ocr_metrics(REAL_VALUES_DF, df)\n",
    "\n",
    "        return df_final.to_csv(full_path + \"/\" + \"opencv_results.csv\", index=False)\n",
    "\n",
    "    def YOLOeasy(self, path, folder_name):\n",
    "        \"\"\"\n",
    "        Use yolov5 to crop the image to exclusively the plate (yolov5_crop_images.ipynb). EasyOCR to transform the plate into text.\n",
    "\n",
    "        Args:\n",
    "            path: directory path which contains the images (cropped images)\n",
    "            folder_name: directory path which will contain the results\n",
    "\n",
    "        Return:\n",
    "            DataFrame.csv with the labeled plate of each car (image)\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.folder_name = folder_name\n",
    "        df_lista_yolo = []\n",
    "\n",
    "        full_path = self.__create_new_folder(path, folder_name)\n",
    "\n",
    "        for dir, subarch, archives in os.walk(path):\n",
    "            for path_image in archives:\n",
    "                try:\n",
    "                    img = cv2.imread(path + \"/\" + str(path_image))\n",
    "                    img = self.__resize_images(img)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    reader = easyocr.Reader([\"en\"])\n",
    "                    result = reader.readtext(img)\n",
    "                    text = result[0][-2]\n",
    "                    df_lista_yolo.append((path_image, text.upper()))\n",
    "\n",
    "                except IndexError as IE:\n",
    "                    print(f\"\\n\\nIndex Error in {path_image}\")\n",
    "                    continue\n",
    "                except Exception as error:\n",
    "                    print(f\"\\n\\nImage Error {path_image}\")\n",
    "                    continue\n",
    "\n",
    "        df_aux = pd.DataFrame(df_lista_yolo)\n",
    "        df_aux.rename(columns={0: \"Image\", 1: \"Plate\"}, inplace=True)\n",
    "        df = df_aux.sort_values(\"Image\").to_csv(\n",
    "            full_path + \"/\" + \"easy_results.csv\", index=False\n",
    "        )\n",
    "        df = pd.read_csv(full_path + \"/\" + \"easy_results.csv\")\n",
    "        df_final = self.__ocr_metrics(REAL_VALUES_DF, df)\n",
    "\n",
    "        return df_final.to_csv(full_path + \"/\" + \"easy_results.csv\", index=False)\n",
    "\n",
    "    def YOLOpytesseract(self, path, folder_name):\n",
    "        \"\"\"\n",
    "        Use yolov5 to crop the image to exclusively the plate (yolov5_crop_images.ipynb). PytesseractOCR to transform the plate into text.\n",
    "\n",
    "        Args:\n",
    "            path: directory path which contains the images (cropped images)\n",
    "            folder_name: directory path which will contain the results\n",
    "\n",
    "        Return:\n",
    "            DataFrame.csv with the labeled plate of each car (image)\n",
    "        \"\"\"\n",
    "        full_path = self.__create_new_folder(path, folder_name)\n",
    "        print(f\"path> {path}\")\n",
    "        processed_path = path + \"processed_images\"\n",
    "        print(f\"processed_path> {processed_path}\")\n",
    "        processed_folder = self.__create_new_folder(processed_path, \"processed_images\")\n",
    "\n",
    "        # Define the configuration for pytesseract\n",
    "        custom_config = r\"--oem 3 --psm 6 -c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "\n",
    "        df_lista_yolo = []\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                try:\n",
    "                    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                        img = cv2.imread(os.path.join(dirpath, filename))\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                        # Use pytesseract to extract text from the image\n",
    "                        text = pytesseract.image_to_string(img, config=custom_config)\n",
    "                        plate = re.sub(r\"[^A-Za-z0-9]+\", \"\", text)\n",
    "                        df_lista_yolo.append((filename, plate.upper()))\n",
    "\n",
    "                except cv2.error as e:\n",
    "                    print(f\"Error reading image file {filename}: {e}\")\n",
    "                except pytesseract.TesseractError as e:\n",
    "                    print(f\"Error processing image file {filename}: {e}\")\n",
    "\n",
    "        # Convert the list to a pandas DataFrame and save to a CSV file\n",
    "        df = pd.DataFrame(df_lista_yolo, columns=[\"Image\", \"Plate\"])\n",
    "        df = df.sort_values(\"Image\").to_csv(\n",
    "            os.path.join(full_path, \"pytesseract_results.csv\"), index=False\n",
    "        )\n",
    "        df = pd.read_csv(os.path.join(full_path, \"pytesseract_results.csv\"))\n",
    "        df_final = self.__ocr_metrics(REAL_VALUES_DF, df)\n",
    "\n",
    "        return df_final.to_csv(\n",
    "            os.path.join(full_path, \"pytesseract_results.csv\"), index=False\n",
    "        )\n",
    "\n",
    "    def YOLOkeras(self, path, folder_name, show_annotations=False):\n",
    "        \"\"\"\n",
    "        Use yolov5 to crop the image to exclusively the plate (yolov5_crop_images.ipynb). KerasOCR to transform the plate into text.\n",
    "\n",
    "        Args:\n",
    "            path: directory path which contains the images\n",
    "            folder_name: directory path which will contain the results\n",
    "\n",
    "        Return:\n",
    "            DataFrame.csv with the labeled plate of each car (image)\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.folder_name = folder_name\n",
    "\n",
    "        full_path = self.__create_new_folder(path, folder_name)\n",
    "\n",
    "        pipeline_list = []\n",
    "        df_keras = []\n",
    "        for dir, subarch, archives in os.walk(path):\n",
    "            for images in archives:\n",
    "                pipeline_list = []\n",
    "                path_images = f\"{dir}/\" + images\n",
    "                pipeline_list.append(path_images)\n",
    "\n",
    "                pipeline = keras_ocr.pipeline.Pipeline()\n",
    "                pipeline_images = [keras_ocr.tools.read(img) for img in pipeline_list]\n",
    "                prediction_groups = pipeline.recognize(pipeline_images)\n",
    "\n",
    "                for content in prediction_groups:\n",
    "                    print(f\"\\n --#-- Analysing {images} --#--\\n\")\n",
    "                    for text, box in content:\n",
    "                        df_keras.append((images, text.upper()))\n",
    "\n",
    "        df_aux = pd.DataFrame(df_keras)\n",
    "        df_aux.rename(columns={0: \"Image\", 1: \"Plate\"}, inplace=True)\n",
    "        df = df_aux.sort_values(\"Image\")\n",
    "        df = df.groupby(\"Image\").sum().to_csv(full_path + \"/\" + \"keras_results.csv\")\n",
    "\n",
    "        if show_annotations == True:\n",
    "            for image, pred in zip(pipeline_images, prediction_groups):\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "                keras_ocr.tools.drawAnnotations(image=image, predictions=pred, ax=ax)\n",
    "\n",
    "        df = pd.read_csv(full_path + \"/\" + \"keras_results.csv\")\n",
    "        df_final = self.__ocr_metrics(REAL_VALUES_DF, df)\n",
    "\n",
    "        return df_final.to_csv(full_path + \"/\" + \"keras_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e25aa29-c553-4d08-a994-cc165650ba8e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have a folder called: results in this directory\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 521ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars104.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 0s 493ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars105.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 0s 495ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars123.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 558ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars14.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars167.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars17.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars197.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 502ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars198.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars199.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars287.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars293.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 546ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars299.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 520ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars301.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars302.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars305.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 539ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars393.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 737ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars418.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars432.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 510ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars52.jpg --#--\n",
      "\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\caio_barros\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 577ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      " --#-- Analysing Cars73.jpg --#--\n",
      "\n",
      "Mean CER = 50.72%\n",
      "Mean WER = 100.0%\n"
     ]
    }
   ],
   "source": [
    "PlateRecognition().YOLOkeras(path=\"cropped_samples/\", folder_name=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6486d86f-c3ef-4c9e-bde3-15a0f8a2eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Folder already created: results\n",
      "path> cropped_samples/\n",
      "processed_path> cropped_samples/processed_images\n",
      "-- Folder already created: processed_images\n",
      "Mean CER = 41.35%\n",
      "Mean WER = 75.0%\n"
     ]
    }
   ],
   "source": [
    "PlateRecognition().YOLOpytesseract(path=\"cropped_samples/\", folder_name=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a83c1ad5-dbb3-49d9-86c1-b29a1d800be0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Folder already created: results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CER = 52.57%\n",
      "Mean WER = 70.0%\n"
     ]
    }
   ],
   "source": [
    "PlateRecognition().YOLOeasy(path=\"cropped_samples/\", folder_name=\"results\")\n",
    "# 52.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce383a31-3efc-4ecb-8803-b4bb581a7242",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Folder already created: results\n",
      "\n",
      "\n",
      "Image Error Cars104.jpg\n",
      "\n",
      "\n",
      "Image Error Cars105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Error in Cars123.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Error in Cars167.jpg\n",
      "\n",
      "\n",
      "Image Error Cars17.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Error in Cars198.jpg\n",
      "\n",
      "\n",
      "Image Error Cars199.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Error in Cars293.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Error in Cars299.jpg\n",
      "\n",
      "\n",
      "Image Error Cars301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image Error Cars305.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Error in Cars432.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image Error Cars104-checkpoint.jpg\n",
      "\n",
      "\n",
      "Image Error Cars105-checkpoint.jpg\n",
      "\n",
      "\n",
      "Image Error Cars123-checkpoint.jpg\n",
      "\n",
      "\n",
      "Image Error Cars299-checkpoint.jpg\n",
      "\n",
      "\n",
      "Image Error Cars418-checkpoint.jpg\n",
      "\n",
      "\n",
      "Image Error Cars52-checkpoint.jpg\n",
      "Mean CER = 41.53%\n",
      "Mean WER = 75.0%\n"
     ]
    }
   ],
   "source": [
    "PlateRecognition().OpenCVeasy(path=\"original_samples/\", folder_name=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21afb25-8e9e-4113-a9b1-cf18a396df2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars104.jpg : 57 x 27\n",
      "Cars105.jpg : 62 x 23\n",
      "Cars123.jpg : 90 x 29\n",
      "Cars14.jpg : 198 x 51\n",
      "Cars167.jpg : 160 x 41\n",
      "Cars17.jpg : 62 x 28\n",
      "Cars197.jpg : 152 x 39\n",
      "Cars198.jpg : 120 x 35\n",
      "Cars199.jpg : 263 x 80\n",
      "Cars287.jpg : 123 x 40\n",
      "Cars293.jpg : 80 x 31\n",
      "Cars299.jpg : 180 x 50\n",
      "Cars301.jpg : 110 x 40\n",
      "Cars302.jpg : 56 x 24\n",
      "Cars305.jpg : 83 x 27\n",
      "Cars393.jpg : 135 x 55\n",
      "Cars418.jpg : 220 x 116\n",
      "Cars432.jpg : 116 x 36\n",
      "Cars52.jpg : 116 x 40\n",
      "Cars73.jpg : 173 x 50\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "diretorio = \"cropped_samples\"  # insira o caminho do diretório aqui\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    if arquivo.endswith(\".jpg\") or arquivo.endswith(\n",
    "        \".png\"\n",
    "    ):  # verifique se o arquivo é uma imagem\n",
    "        imagem = Image.open(os.path.join(diretorio, arquivo))  # abra a imagem\n",
    "        largura, altura = imagem.size  # obtenha a largura e altura da imagem\n",
    "        print(\n",
    "            arquivo, \":\", largura, \"x\", altura\n",
    "        )  # exiba o nome do arquivo e seu tamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b49da9e-74ac-45b6-a72e-229bbd0cae40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "diretorio = \"cropped_samples\"  # insira o caminho do diretório aqui\n",
    "novo_diretorio = \"teste_samples\"  # insira o caminho para o novo diretório aqui\n",
    "tamanho_limite = (200, 200)  # insira o tamanho limite para as imagens aqui\n",
    "\n",
    "if not os.path.exists(novo_diretorio):\n",
    "    os.makedirs(novo_diretorio)\n",
    "\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    if arquivo.endswith(\".jpg\") or arquivo.endswith(\n",
    "        \".png\"\n",
    "    ):  # verifique se o arquivo é uma imagem\n",
    "        imagem = Image.open(os.path.join(diretorio, arquivo))  # abra a imagem\n",
    "        largura, altura = imagem.size  # obtenha a largura e altura da imagem\n",
    "        if (\n",
    "            largura <= tamanho_limite[0] and altura <= tamanho_limite[1]\n",
    "        ):  # verifique se a imagem é pequena\n",
    "            nova_imagem = imagem.resize(\n",
    "                tamanho_limite, resample=Image.LANCZOS\n",
    "            )  # redimensione a imagem mantendo a qualidade\n",
    "            nome_arquivo, extensao_arquivo = os.path.splitext(arquivo)\n",
    "            novo_arquivo = (\n",
    "                nome_arquivo + \"_nova\" + extensao_arquivo\n",
    "            )  # crie um novo nome de arquivo\n",
    "            novo_caminho = os.path.join(\n",
    "                novo_diretorio, novo_arquivo\n",
    "            )  # crie o caminho para o novo arquivo\n",
    "            nova_imagem.save(\n",
    "                novo_caminho\n",
    "            )  # salve a nova imagem com o mesmo formato e nome da imagem original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "834262c9-ab37-4a1e-b4a7-6d94dd478ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import os\n",
    "\n",
    "diretorio = \"cropped_samples\"  # insira o caminho do diretório aqui\n",
    "novo_diretorio = \"teste_samples\"  # insira o caminho para o novo diretório aqui\n",
    "\n",
    "if not os.path.exists(novo_diretorio):\n",
    "    os.makedirs(novo_diretorio)\n",
    "\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    if arquivo.endswith(\".jpg\") or arquivo.endswith(\n",
    "        \".png\"\n",
    "    ):  # verifique se o arquivo é uma imagem\n",
    "        imagem = Image.open(os.path.join(diretorio, arquivo))  # abra a imagem\n",
    "        imagem_nitida = imagem.filter(\n",
    "            ImageFilter.SMOOTH\n",
    "        )  # aplique um filtro de nitidez para melhorar a definição das placas\n",
    "        novo_caminho = os.path.join(\n",
    "            novo_diretorio, arquivo\n",
    "        )  # crie o caminho para o novo arquivo\n",
    "        imagem_nitida.save(\n",
    "            novo_caminho\n",
    "        )  # salve a nova imagem com o mesmo formato e nome da imagem original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c5e6031-4cb0-4976-bc21-5c28842f3594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Folder already created: results\n",
      "Mean CER = 26.26%\n",
      "Mean WER = 85.0%\n"
     ]
    }
   ],
   "source": [
    "PlateRecognition().YOLOpytesseract(path=\"teste_samples/\", folder_name=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8719c8d-c9b5-4f0b-8534-6bd63e3a3d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "directory = \"cropped_samples\"  # altere para o caminho do seu diretório\n",
    "new_width = 115\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\n",
    "        \".png\"\n",
    "    ):  # altere de acordo com o formato das suas imagens\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        if width < new_width:\n",
    "            new_height = int(height * new_width / width)\n",
    "            img = img.resize((new_width, new_height))\n",
    "\n",
    "        # Aplica aumento de contraste na imagem\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        enhanced_img = enhancer.enhance(\n",
    "            2.0\n",
    "        )  # altere o fator de aumento de contraste conforme necessário\n",
    "\n",
    "        # Salva a imagem com o mesmo nome e formato de antes, em um novo diretório\n",
    "        output_dir = \"teste_samples\"  # altere para o caminho do seu diretório de saída\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        enhanced_img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1772165-d79b-4617-8f91-70995b34826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __preprocess_images(self, image):\n",
    "    new_width = 115\n",
    "    width, height = img.size\n",
    "        if width < new_width:\n",
    "            new_height = int(height * new_width / width)\n",
    "            img = img.resize((new_width, new_height))\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    enhanced_img = enhancer.enhance(2.0)\n",
    "    return enhanced_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
